{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd6f36b0",
   "metadata": {},
   "source": [
    "# Neural network for dose measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d031b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib tk\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import NNPytorchLightning as NNPL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a04e66",
   "metadata": {},
   "source": [
    "Here loading trained models to compare the training and validation losses per model, and look at performance on unseen data. These models are as follows:\n",
    "\n",
    "model_cubes: trained just on cube counts, with a batch size of 200 and 200 samples per data set, learning rate of 1e-3, for 500 epochs (for time)\n",
    "\n",
    "model_cubes_profiles: trained on cube counts and profiles, with a batch size of 200 and 200 samples per data set, learning rate of 1e-3, for 500 epochs (for time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a47ea1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = '/home/nr1315/Documents/Project/effective_dose_coeffs.h5'\n",
    "energy_bins = '/home/nr1315/Documents/Project/MachineLearning/energy_bins.npy'\n",
    "\n",
    "model_cubes = NNPL.LoadModel('/home/nr1315/Documents/Project/MachineLearning/lightning_logs/model_cubes_new_data/version_1/',torch.rand((1,1,64)),coeffs,energy_bins)\n",
    "\n",
    "model_cubes_profiles = NNPL.LoadModel('/home/nr1315/Documents/Project/MachineLearning/lightning_logs/model_cubes_profiles_new_data/version_5/',torch.rand((1,1,76)),coeffs,energy_bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bed94dd",
   "metadata": {},
   "source": [
    "Also need to load the loss curves separately, due to the way they are from the logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a405991",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cubes_tloss = pd.read_csv('/home/nr1315/Downloads/run-model_cubes_new_data_version_1-tag-train_loss.csv')\n",
    "model_cubes_vloss = pd.read_csv('/home/nr1315/Downloads/run-model_cubes_new_data_version_1-tag-val_loss.csv')\n",
    "\n",
    "model_cubes_profiles_tloss = pd.read_csv('/home/nr1315/Downloads/run-model_cubes_profiles_new_data_version_5-tag-train_loss.csv')\n",
    "model_cubes_profiles_vloss = pd.read_csv('/home/nr1315/Downloads/run-model_cubes_profiles_new_data_version_5-tag-val_loss.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9939c8bc",
   "metadata": {},
   "source": [
    "We also define the directories from which to load the testing data, for convenience:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "999beda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data_dir = '/home/nr1315/Documents/Project/MachineLearning/TestingData/'\n",
    "\n",
    "AmBe_counts = 'SimCubeCounts_AmBe_5_0-0-0-0-1-0_1500.npy'\n",
    "AmLi_counts = 'SimCubeCounts_AmLi_5_0-0-0-0-1-0_1500.npy'\n",
    "Cf_counts = 'SimCubeCounts_Cf252_6_0-0-0-0-1-0_1500.npy'\n",
    "\n",
    "AmBe_target = 'SimEnergyBins_AmBe.npy'\n",
    "AmLi_target = 'SimEnergyBins_AmLi.npy'\n",
    "Cf_target = 'SimEnergyBins_Cf252.npy'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9908db3",
   "metadata": {},
   "source": [
    "For each model in turn, we will look at the loss curves and prediction on AmBe, AmLi, and Cf-252. \n",
    "\n",
    "### Cubes only model, 500 epochs, 200 samples per dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f27b4824",
   "metadata": {},
   "outputs": [],
   "source": [
    "NNPL.PlotLosses([model_cubes_tloss,model_cubes_vloss],['Training loss','Validation loss'],'Model with only cube counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505dd294",
   "metadata": {},
   "source": [
    "![Loss curves](Plots/model_cubes_loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1e4328",
   "metadata": {},
   "source": [
    "Here the model seems to be training well, although it does not appear to finish training after 500 epochs. \n",
    "\n",
    "We now look at the model prediction quality on some unseen data, using the compare_pred_true function. This also returns the testing loss of the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ce27fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,3,figsize=(30,10))\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "l1 = NNPL.compare_pred_true(model_cubes,testing_data_dir+AmBe_counts,testing_data_dir+AmBe_target,'AmBe','cubes only model',ax[0],24,np.load(energy_bins),1,loss_fn)\n",
    "l2 = NNPL.compare_pred_true(model_cubes,testing_data_dir+AmLi_counts,testing_data_dir+AmLi_target,'AmLi','cubes only model',ax[1],24,np.load(energy_bins),1,loss_fn)\n",
    "l3 = NNPL.compare_pred_true(model_cubes,testing_data_dir+Cf_counts,testing_data_dir+Cf_target,r'$^{252}$Cf','cubes only model',ax[2],24,np.load(energy_bins),1,loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238cd8d2",
   "metadata": {},
   "source": [
    "![Predictions of test data](Plots/simulated_predictions_cubes_model.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bcc7e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AmBe loss: 0.0878705158829689\n",
      "AmLi loss: 0.04326992481946945\n",
      "Cf-252 loss: 0.017681293189525604\n"
     ]
    }
   ],
   "source": [
    "print(\"AmBe loss: {}\".format(l1))\n",
    "print(\"AmLi loss: {}\".format(l2))\n",
    "print(\"Cf-252 loss: {}\".format(l3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fe0286",
   "metadata": {},
   "source": [
    "Whilst the model loss continues to decrease, the model still has poor performance on the unseen sources, generally predicting lower energies than the source actually is, and also predicting negative values in at least half the bins in all three cases. It is then informative to see the performance of the model on some of the validation data explicitly, as is shown below. The function used to plot this can be used to scroll through all of the training datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79942c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from NNPytorchLightning import FluenceReconDataset, Resample\n",
    "\n",
    "cubes_dataloader = torch.load('/home/nr1315/Documents/Project/MachineLearning/lightning_logs/model_cubes_new_data/version_1/val_dloader.pt')\n",
    "cubes_dataset,cubes_val_inds = cubes_dataloader.dataset.dataset,cubes_dataloader.dataset.indices\n",
    "\n",
    "check = NNPL.CheckTrainData(model_cubes,cubes_dataset,np.load(energy_bins))\n",
    "\n",
    "check.ViewTrainData()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548bce26",
   "metadata": {},
   "source": [
    "![550keV model cubes pred](Plots/model_cubes_550keV_pred.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f532f0",
   "metadata": {},
   "source": [
    "The model has generally performed well at predicting the bins for this validation data point with some count in an incorrect bin, but of note is that it is still predicting negative values in several bins. In order to avoid this, it may prove useful to add a term to the loss function that penalises any negative bins in the model prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec887dc",
   "metadata": {},
   "source": [
    "### Cubes and profiles model, 200 samples per dataset, learning rate 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d33d5ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "NNPL.PlotLosses([model_cubes_profiles_tloss,model_cubes_profiles_vloss],['Training loss','Validation loss'],'Cubes and profiles model, lr = 0.001, 200 samples per dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c15676b",
   "metadata": {},
   "source": [
    "![losses](Plots/model_cubes_profiles_200samples.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0ee180",
   "metadata": {},
   "source": [
    "Whilst both the training loss and validation loss do both decrease, it is worth noting that the validation loss here is lower than the training loss, which in turn implies that the model needs to train for longer in this configuration. This is intuitive, as the increased number of bins due to the profile counts will mean there are a greater number of weights for the model to optimize. Other improvements may be found from increasing the learning rate or adding some learning rate scheduling, but otherwise training for longer is realistically required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c20cae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,3,figsize=(30,10))\n",
    "\n",
    "l4 = NNPL.compare_pred_true(model_cubes_profiles,testing_data_dir+'withProfiles/'+AmBe_counts,testing_data_dir+AmBe_target,'AmBe','cubes and \\n profiles model',ax[0],24,np.load(energy_bins),1,loss_fn)\n",
    "l5 = NNPL.compare_pred_true(model_cubes_profiles,testing_data_dir+'withProfiles/'+AmLi_counts,testing_data_dir+AmLi_target,'AmLi','cubes and \\n profiles model',ax[1],24,np.load(energy_bins),1,loss_fn)\n",
    "l6 = NNPL.compare_pred_true(model_cubes_profiles,testing_data_dir+'withProfiles/'+Cf_counts,testing_data_dir+Cf_target,r'$^{252}$Cf','cubes and \\n profiles model',ax[2],24,np.load(energy_bins),1,loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c48bee",
   "metadata": {},
   "source": [
    "![cubes profiles 200 samples prediction](Plots/model_cubes_profiles_200samples_prediction.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6c1b932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AmBe loss: 0.0343862809240818\n",
      "AmLi loss: 0.023080822080373764\n",
      "Cf-252 loss: 0.020924247801303864\n"
     ]
    }
   ],
   "source": [
    "print(\"AmBe loss: {}\".format(l4))\n",
    "print(\"AmLi loss: {}\".format(l5))\n",
    "print(\"Cf-252 loss: {}\".format(l6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba312d44",
   "metadata": {},
   "source": [
    "Similar to the cubes model, the model performs poorly on the unseen data, although it does have a better loss value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377b0678",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
