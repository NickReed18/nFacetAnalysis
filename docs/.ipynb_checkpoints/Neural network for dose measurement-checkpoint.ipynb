{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd6f36b0",
   "metadata": {},
   "source": [
    "# Neural network for dose measurement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81434f7f",
   "metadata": {},
   "source": [
    "### Introduction and motivation\n",
    "In modern dosimetry, the gold standard of radiation dose measurement is _effective dose_. This quantity is defined as a sum over dose to each major organ in the human body, weighted by a set of _tissue weighting factors_ that encode the average risk to health of a dose to that organ. This is a complex and difficult measurement to make, as many modern dosimeters are either optimised for field direction measurement or a fluence measurement. For example, for a Bonner sphere spectrometer, measuring effective dose is a time-consuming and computationally intensive process that requires careful measurement of the radiation field with varying size of polyethylene sphere and a complex unfolding algorithm to reconstruct the fluence, and this still lacks directional information about the field. \n",
    "\n",
    "In contrast, the segmentation of nFacet 3D encodes both the direction and the energy of an incident neutron field. This can be visualised through the direction and intensity of attenuation of neutron count in the detector cubes. There are therefore two components to measuring the effective dose: reconstructing the fluence of the incident neutron field, and the direction of incidence of the neutrons. Here I focus on the fluence reconstruction using an artificial neural network (ANN), as once trained this is a fast method for reconstructing the fluence without need for a complex unfolding algorithm. \n",
    "\n",
    "### Neural network architecture\n",
    "\n",
    "The information for the network to learn is encoded in the distribution of neutron count across cubes in the detector. As a result, the first choice of input into the network consisted of 64 input neurons corresponding to the 64 cubes of the detector, whilst the output of the ANN was the binned fluence of the source. Additionally, summing the counts in planes of cubes provides additional information about the bulk response of the detector to the applied field and thus encodes more detailed information about the energy of the incident neutrons. This can be added to the inputs, adding 12 additional neurons corresponding to the four planes in the x, y and z directions. The model has subsequently been trained with and without these additional inputs to evaluate performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc316b4d",
   "metadata": {},
   "source": [
    "### Fluence binning scheme\n",
    "\n",
    "TO BE ADDED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "id": "5d031b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "%matplotlib tk\n",
    "\n",
    "import NNPytorchLightning as NNPL\n",
    "from NNPytorchLightning import FluenceReconDataset, Resample\n",
    "\n",
    "\n",
    "import warnings\n",
    "from scipy.integrate import quad,IntegrationWarning\n",
    "from scipy.interpolate import interp1d\n",
    "warnings.simplefilter(action='ignore', category=IntegrationWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a04e66",
   "metadata": {},
   "source": [
    "Here loading trained models to compare the training and validation losses per model, and look at performance on unseen data. These models are as follows:\n",
    "\n",
    "model_cubes: trained just on cube counts, with a batch size of 200 and 200 samples per data set, learning rate of 1e-3, for 500 epochs (for time)\n",
    "\n",
    "model_cubes_profiles: trained on cube counts and profiles, with a batch size of 200 and 200 samples per data set, learning rate of 1e-3, for 500 epochs (for time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a47ea1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = '/home/nr1315/Documents/Project/effective_dose_coeffs.h5'\n",
    "energy_bins = '/home/nr1315/Documents/Project/MachineLearning/energy_bins.npy'\n",
    "\n",
    "model_cubes = NNPL.LoadModel('/home/nr1315/Documents/Project/MachineLearning/lightning_logs/model_cubes_new_data/version_1/',torch.rand((1,1,64)),coeffs,energy_bins)\n",
    "\n",
    "model_cubes_profiles = NNPL.LoadModel('/home/nr1315/Documents/Project/MachineLearning/lightning_logs/model_cubes_profiles_new_data/version_5/',torch.rand((1,1,76)),coeffs,energy_bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bed94dd",
   "metadata": {},
   "source": [
    "Also need to load the loss curves separately, due to the way they are from the logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a405991",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cubes_tloss = pd.read_csv('/home/nr1315/Documents/Project/MachineLearning/LoggedParameters/run-model_cubes_new_data_version_1-tag-train_loss.csv')\n",
    "model_cubes_vloss = pd.read_csv('/home/nr1315/Documents/Project/MachineLearning/LoggedParameters/run-model_cubes_new_data_version_1-tag-val_loss.csv')\n",
    "model_cubes_dose_err = pd.read_csv('/home/nr1315/Documents/Project/MachineLearning/LoggedParameters/run-model_cubes_new_data_version_1-tag-dose_err_AP.csv')\n",
    "model_cubes_epoch = pd.read_csv('/home/nr1315/Documents/Project/MachineLearning/LoggedParameters/run-model_cubes_new_data_version_1-tag-epoch.csv')\n",
    "\n",
    "model_cubes_profiles_tloss = pd.read_csv('/home/nr1315/Documents/Project/MachineLearning/LoggedParameters/run-model_cubes_profiles_new_data_version_5-tag-train_loss.csv')\n",
    "model_cubes_profiles_vloss = pd.read_csv('/home/nr1315/Documents/Project/MachineLearning/LoggedParameters/run-model_cubes_profiles_new_data_version_5-tag-val_loss.csv')\n",
    "model_cubes_profiles_dose_err = pd.read_csv('/home/nr1315/Documents/Project/MachineLearning/LoggedParameters/run-model_cubes_profiles_new_data_version_5-tag-dose_err_AP.csv')\n",
    "model_cubes_profiles_epoch = pd.read_csv('/home/nr1315/Documents/Project/MachineLearning/LoggedParameters/run-model_cubes_profiles_new_data_version_5-tag-epoch.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9939c8bc",
   "metadata": {},
   "source": [
    "We also define the directories from which to load the testing data, for convenience:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "999beda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data_dir = '/home/nr1315/Documents/Project/MachineLearning/TestingData/'\n",
    "\n",
    "AmBe_counts = 'SimCubeCounts_AmBe_5_0-0-0-0-1-0_1500.npy'\n",
    "AmLi_counts = 'SimCubeCounts_AmLi_5_0-0-0-0-1-0_1500.npy'\n",
    "Cf_counts = 'SimCubeCounts_Cf252_6_0-0-0-0-1-0_1500.npy'\n",
    "\n",
    "AmBe_target = 'SimEnergyBins_AmBe.npy'\n",
    "AmLi_target = 'SimEnergyBins_AmLi.npy'\n",
    "Cf_target = 'SimEnergyBins_Cf252.npy'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9908db3",
   "metadata": {},
   "source": [
    "For each model in turn, we will look at the loss curves and prediction on AmBe, AmLi, and Cf-252. \n",
    "\n",
    "### Cubes only model, 500 epochs, 200 samples per dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f27b4824",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nr1315/miniconda3/envs/NewMLEnv/lib/python3.9/site-packages/scipy/interpolate/interpolate.py:623: RuntimeWarning: invalid value encountered in true_divide\n",
      "  slope = (y_hi - y_lo) / (x_hi - x_lo)[:, None]\n",
      "/home/nr1315/miniconda3/envs/NewMLEnv/lib/python3.9/site-packages/scipy/interpolate/interpolate.py:623: RuntimeWarning: invalid value encountered in true_divide\n",
      "  slope = (y_hi - y_lo) / (x_hi - x_lo)[:, None]\n"
     ]
    }
   ],
   "source": [
    "NNPL.PlotLosses([model_cubes_tloss,model_cubes_vloss],['Training loss','Validation loss'],'Cubes model, lr = 0.001, 200 samples per dataset',model_cubes_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaf6301",
   "metadata": {},
   "source": [
    "![Loss curves](Plots/model_cubes_loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1e4328",
   "metadata": {},
   "source": [
    "Here the model seems to be training well, although it does not appear to finish training after 500 epochs. \n",
    "\n",
    "It is also informative to look at the quality of model prediction on unseen data, in this case AmLi, AmBe, and Cf252 sources. These can be seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ce27fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,3,figsize=(30,10))\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "AmBe_loss,AmBe_dose_err = NNPL.compare_pred_true(model_cubes,testing_data_dir+AmBe_counts,testing_data_dir+AmBe_target,'AmBe','cubes only model',ax[0],24,np.load(energy_bins),1,loss_fn,'AP')\n",
    "AmLi_loss,AmLi_dose_err = NNPL.compare_pred_true(model_cubes,testing_data_dir+AmLi_counts,testing_data_dir+AmLi_target,'AmLi','cubes only model',ax[1],24,np.load(energy_bins),1,loss_fn,'AP')\n",
    "Cf_loss,Cf_dose_err = NNPL.compare_pred_true(model_cubes,testing_data_dir+Cf_counts,testing_data_dir+Cf_target,r'$^{252}$Cf','cubes only model',ax[2],24,np.load(energy_bins),1,loss_fn,'AP')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238cd8d2",
   "metadata": {},
   "source": [
    "![Predictions of test data](Plots/model_cubes_prediction.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41248250",
   "metadata": {},
   "source": [
    "| Source | Model type | Number of training epochs | Abosolute percentage dose error|\n",
    "| ---   | -----| ---- | ----- |\n",
    "| AmBe | Cubes | 500 | 0.7% |\n",
    "| |Cubes | 2000 | 1.3% |\n",
    "| | Cubes and profiles | 500 | 1.0% |\n",
    "| | Cubes and profiles | 2000 | 3.35% |\n",
    "| AmLi | Cubes | 500 | 11.5% |\n",
    "| | Cubes | 2000 | 18.0% |\n",
    "| | Cubes and profiles | 500 | 3.2% |\n",
    "| | Cubes and profiles | 2000 | 1.25% |\n",
    "| Cf | Cubes | 500 | 3.8% |\n",
    "| | Cubes | 2000 | 5.6% |\n",
    "| | Cubes and profiles | 500 | 7.4% |\n",
    "| | Cubes and profiles | 2000 | 0.89%\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fe0286",
   "metadata": {},
   "source": [
    "Whilst the model loss continues to decrease, the model still has poor performance on the unseen sources,  predicting negative values in at least half the bins in all three cases. It generally seems to predict the greatest count in the region around the average energy of each source, i.e. above, below and at 1 MeV for AmBe, AmLi and Cf respectively, as previous iterations of the model did. One possible way to combat this may be to introduce more complex sources into the training set, such as linear combinations of existing monoenergetics, to help the network learn how to better reconstruct a more complicated fluence.\n",
    "\n",
    "It is then informative to see the performance of the model on some of the validation data explicitly, as is shown below. The function used to plot this can be used to scroll through all of the training datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79942c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cubes_dataloader = torch.load('/home/nr1315/Documents/Project/MachineLearning/lightning_logs/model_cubes_new_data/version_1/val_dloader.pt')\n",
    "cubes_dataset,cubes_val_inds = cubes_dataloader.dataset.dataset,cubes_dataloader.dataset.indices\n",
    "\n",
    "check = NNPL.CheckTrainData(model_cubes,cubes_dataset,np.load(energy_bins))\n",
    "\n",
    "check.ViewTrainData()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548bce26",
   "metadata": {},
   "source": [
    "![550keV model cubes pred](Plots/model_cubes_550keV_pred.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f532f0",
   "metadata": {},
   "source": [
    "The model has generally performed well at predicting the bins for this validation data point with some count in an incorrect bin, but of note is that it is still predicting negative values in several bins. In order to avoid this, it may prove useful to add a term to the loss function that penalises any negative bins in the model prediction. \n",
    "\n",
    "A more thorough check of the validation data set for both this model and the following will be performed later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec887dc",
   "metadata": {},
   "source": [
    "### Cubes and profiles model, 200 samples per dataset, learning rate 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d33d5ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nr1315/miniconda3/envs/NewMLEnv/lib/python3.9/site-packages/scipy/interpolate/interpolate.py:623: RuntimeWarning: invalid value encountered in true_divide\n",
      "  slope = (y_hi - y_lo) / (x_hi - x_lo)[:, None]\n",
      "/home/nr1315/miniconda3/envs/NewMLEnv/lib/python3.9/site-packages/scipy/interpolate/interpolate.py:623: RuntimeWarning: invalid value encountered in true_divide\n",
      "  slope = (y_hi - y_lo) / (x_hi - x_lo)[:, None]\n"
     ]
    }
   ],
   "source": [
    "NNPL.PlotLosses([model_cubes_profiles_tloss,model_cubes_profiles_vloss],['Training loss','Validation loss'],'Cubes and profiles model, lr = 0.001, 200 samples per dataset',model_cubes_profiles_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c15676b",
   "metadata": {},
   "source": [
    "![losses](Plots/model_cubes_profiles_200samples.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0ee180",
   "metadata": {},
   "source": [
    "Whilst both the training loss and validation loss do both decrease, it is worth noting that the validation loss here is lower than the training loss, which in turn implies that the model needs to train for longer in this configuration. This is intuitive, as the increased number of bins due to the profile counts will mean there are a greater number of weights for the model to optimize. Other improvements may be found from increasing the learning rate or adding some learning rate scheduling, but otherwise training for longer is realistically required.\n",
    "\n",
    "It is also worthy of note that the loss is higher than for the cubes-only model, but this may be a factor of the incomplete training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c20cae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,3,figsize=(30,10))\n",
    "\n",
    "cp_AmBe_loss,cp_AmBe_dose_err = NNPL.compare_pred_true(model_cubes_profiles,testing_data_dir+'withProfiles/'+AmBe_counts,testing_data_dir+AmBe_target,'AmBe','cubes and \\n profiles model',ax[0],24,np.load(energy_bins),1,loss_fn,'AP')\n",
    "cp_AmLi_loss,cp_AmLi_dose_err = NNPL.compare_pred_true(model_cubes_profiles,testing_data_dir+'withProfiles/'+AmLi_counts,testing_data_dir+AmLi_target,'AmLi','cubes and \\n profiles model',ax[1],24,np.load(energy_bins),1,loss_fn,'AP')\n",
    "cp_Cf_loss,cp_Cf_dose_err = NNPL.compare_pred_true(model_cubes_profiles,testing_data_dir+'withProfiles/'+Cf_counts,testing_data_dir+Cf_target,r'$^{252}$Cf','cubes and \\n profiles model',ax[2],24,np.load(energy_bins),1,loss_fn,'AP')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c48bee",
   "metadata": {},
   "source": [
    "![cubes profiles 200 samples prediction](Plots/model_cubes_profiles_200samples_prediction.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2596e5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AmBe dose error: 1.065460692649702\n",
      "AmLi dose error: 3.1880135887862817\n",
      "Cf dose error: 7.416363308539327\n"
     ]
    }
   ],
   "source": [
    "print(\"AmBe dose error: {}\".format(100*cp_AmBe_dose_err))\n",
    "print(\"AmLi dose error: {}\".format(100*cp_AmLi_dose_err))\n",
    "print(\"Cf dose error: {}\".format(100*cp_Cf_dose_err))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba312d44",
   "metadata": {},
   "source": [
    "This model also performs poorly on the unseen data, although it has a lower loss than the cubes exclusive model. Most notably, this model predicts a large negative value in the first bin for all three sources, which further motivates introducing a penalty term to the loss to discourage any negative values in the model output. \n",
    "\n",
    "\n",
    "Validation data set checking needs some more work before conclusions can be drawn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "377b0678",
   "metadata": {},
   "outputs": [],
   "source": [
    "cubes_profiles_dataloader = torch.load('/home/nr1315/Documents/Project/MachineLearning/lightning_logs/model_cubes_profiles_new_data/version_5/val_dloader.pt')\n",
    "cubes_profiles_dataset,cubes_profiles_val_inds = cubes_profiles_dataloader.dataset.dataset,cubes_profiles_dataloader.dataset.indices\n",
    "\n",
    "check = NNPL.CheckTrainData(model_cubes_profiles,cubes_profiles_dataset,np.load(energy_bins))\n",
    "\n",
    "check.ViewTrainData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aae42c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e496bb01",
   "metadata": {},
   "source": [
    "After these results both models were trained again for 2000 epochs, as it appeared that neither model had fully trained in the 500 epochs here. These models and the monitoring quantities are loaded in here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59b0a3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cubes_2000 = NNPL.LoadModel('/home/nr1315/Documents/Project/MachineLearning/lightning_logs/model_cubes_new_data/version_4/',torch.rand((1,1,64)),coeffs,energy_bins)\n",
    "\n",
    "model_cubes_profiles_2000 = NNPL.LoadModel('/home/nr1315/Documents/Project/MachineLearning/lightning_logs/model_cubes_profiles_new_data/version_11/',torch.rand((1,1,76)),coeffs,energy_bins)\n",
    "\n",
    "model_cubes_2000_tloss = pd.read_csv('/home/nr1315/Documents/Project/MachineLearning/LoggedParameters/run-model_cubes_new_data_version_4-tag-train_loss.csv')\n",
    "model_cubes_2000_vloss = pd.read_csv('/home/nr1315/Documents/Project/MachineLearning/LoggedParameters/run-model_cubes_new_data_version_4-tag-val_loss.csv')\n",
    "model_cubes_2000_dose_err = pd.read_csv('/home/nr1315/Documents/Project/MachineLearning/LoggedParameters/run-model_cubes_new_data_version_4-tag-dose_err_AP.csv')\n",
    "model_cubes_2000_epoch = pd.read_csv('/home/nr1315/Documents/Project/MachineLearning/LoggedParameters/run-model_cubes_new_data_version_4-tag-epoch.csv')\n",
    "\n",
    "model_cubes_profiles_2000_tloss = pd.read_csv('/home/nr1315/Documents/Project/MachineLearning/LoggedParameters/run-model_cubes_profiles_new_data_version_11-tag-train_loss.csv')\n",
    "model_cubes_profiles_2000_vloss = pd.read_csv('/home/nr1315/Documents/Project/MachineLearning/LoggedParameters/run-model_cubes_profiles_new_data_version_11-tag-val_loss.csv')\n",
    "model_cubes_profiles_2000_dose_err = pd.read_csv('/home/nr1315/Documents/Project/MachineLearning/LoggedParameters/run-model_cubes_profiles_new_data_version_11-tag-dose_err_AP.csv')\n",
    "\n",
    "model_cubes_profiles_2000_epoch = pd.read_csv('/home/nr1315/Documents/Project/MachineLearning/LoggedParameters/run-model_cubes_profiles_new_data_version_11-tag-epoch.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db007d47",
   "metadata": {},
   "source": [
    "### Cubes model, learning rate 0.001, 200 samples per dataset, trained for 2000 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67448e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "NNPL.PlotLosses([model_cubes_2000_tloss,model_cubes_2000_vloss],['Training loss','Validation loss'],'Cubes model, lr = 0.001, 200 samples per dataset, 2000 epochs',model_cubes_2000_epoch,log=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0864ef42",
   "metadata": {},
   "source": [
    "![model cubes 2000epochs loss](Plots/model_cubes_2000_loss.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b7a4d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "NNPL.PlotDoseError(model_cubes_2000_dose_err,'Cubes model, lr = 0.001, 200 samples per dataset, 2000 epochs, dose error',model_cubes_2000_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630b5532",
   "metadata": {},
   "source": [
    "![model cubes 2000 dose error](Plots/model_cubes_2000_dose_err.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1d26b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,3,figsize=(30,10))\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "cubes_2000_AmBe_loss,cubes_2000_AmBe_dose_err = NNPL.compare_pred_true(model_cubes_2000,testing_data_dir+AmBe_counts,testing_data_dir+AmBe_target,'AmBe','cubes only model,\\n 2000 epochs',ax[0],24,np.load(energy_bins),1,loss_fn,'AP')\n",
    "cubes_2000_AmLi_loss,cubes_2000_AmLi_dose_err = NNPL.compare_pred_true(model_cubes_2000,testing_data_dir+AmLi_counts,testing_data_dir+AmLi_target,'AmLi','cubes only model,\\n 2000 epochs',ax[1],24,np.load(energy_bins),1,loss_fn,'AP')\n",
    "cubes_2000_Cf_loss,cubes_2000_Cf_dose_err = NNPL.compare_pred_true(model_cubes_2000,testing_data_dir+Cf_counts,testing_data_dir+Cf_target,r'$^{252}$Cf','cubes only model,\\n 2000 epochs',ax[2],24,np.load(energy_bins),1,loss_fn,'AP')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ffcf5e",
   "metadata": {},
   "source": [
    "![cubes model 2000 predictions](Plots/model_cubes_2000_prediction_1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fa730cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AmBe loss: 0.0924101173877716\n",
      "AmLi loss: 0.02471756935119629\n",
      "Cf-252 loss: 0.034533705562353134\n"
     ]
    }
   ],
   "source": [
    "print(\"AmBe loss: {}\".format(cubes_2000_AmBe_loss))\n",
    "print(\"AmLi loss: {}\".format(cubes_2000_AmLi_loss))\n",
    "print(\"Cf-252 loss: {}\".format(cubes_2000_Cf_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "742dab7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AmBe 1.2531776280353704\n",
      "AmLi 17.97001801529823\n",
      "Cf 5.568272436953861\n"
     ]
    }
   ],
   "source": [
    "print(\"AmBe {}\".format(100*cubes_2000_AmBe_dose_err))\n",
    "print(\"AmLi {}\".format(100*cubes_2000_AmLi_dose_err))\n",
    "print(\"Cf {}\".format(100*cubes_2000_Cf_dose_err))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f713611e",
   "metadata": {},
   "source": [
    "### Cubes and profiles model, learning rate 0.001, 200 samples per dataset, trained for 2000 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b2f345a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NNPL.PlotLosses([model_cubes_profiles_2000_tloss,model_cubes_profiles_2000_vloss],['Training loss','Validation loss'],'Cubes and profiles model, lr = 0.001, 200 samples per dataset, 2000 epochs',model_cubes_profiles_2000_epoch,log=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5569e771",
   "metadata": {},
   "source": [
    "![Cubes profiles 2000 epochs loss](Plots/model_cubes_profiles_2000epochs_loss.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66c9334c",
   "metadata": {},
   "outputs": [],
   "source": [
    "NNPL.PlotDoseError(model_cubes_profiles_2000_dose_err,'Cubes and profiles model dose error',model_cubes_profiles_2000_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf721d8",
   "metadata": {},
   "source": [
    "![cubes profiles 2000 epochs dose error](Plots/model_cubes_profiles_2000epochs_dose_err.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9fd0dca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1,3,figsize=(30,10))\n",
    "\n",
    "cubes_profiles_2000_AmBe_loss,cp_2000_AmBe_dose_err = NNPL.compare_pred_true(model_cubes_profiles_2000,testing_data_dir+'withProfiles/'+AmBe_counts,testing_data_dir+AmBe_target,'AmBe','cubes and \\n profiles model, 2000 epochs',ax[0],24,np.load(energy_bins),1,loss_fn,'AP')\n",
    "cubes_profiles_2000_AmLi_loss,cp_2000_AmLi_dose_err = NNPL.compare_pred_true(model_cubes_profiles_2000,testing_data_dir+'withProfiles/'+AmLi_counts,testing_data_dir+AmLi_target,'AmLi','cubes and \\n profiles model, 2000 epochs',ax[1],24,np.load(energy_bins),1,loss_fn,'AP')\n",
    "cubes_profiles_2000_Cf_loss,cp_2000_Cf_dose_err = NNPL.compare_pred_true(model_cubes_profiles_2000,testing_data_dir+'withProfiles/'+Cf_counts,testing_data_dir+Cf_target,r'$^{252}$Cf','cubes and \\n profiles model, 2000 epochs',ax[2],24,np.load(energy_bins),1,loss_fn,'AP')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78586d47",
   "metadata": {},
   "source": [
    "![cubes profiles 2000 predictions](Plots/model_cubes_profiles_2000_prediction.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4844a4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AmBe loss: 0.10277150571346283\n",
      "AmLi loss: 0.05674799904227257\n",
      "Cf-252 loss: 0.03377455845475197\n"
     ]
    }
   ],
   "source": [
    "print(\"AmBe loss: {}\".format(cubes_profiles_2000_AmBe_loss))\n",
    "print(\"AmLi loss: {}\".format(cubes_profiles_2000_AmLi_loss))\n",
    "print(\"Cf-252 loss: {}\".format(cubes_profiles_2000_Cf_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58e3e716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AmBe: 3.3541519263668786\n",
      "AmLi: 1.2462487568431224\n",
      "Cf: 0.891351256055962\n"
     ]
    }
   ],
   "source": [
    "print(\"AmBe: {}\".format(cp_2000_AmBe_dose_err*100))\n",
    "print(\"AmLi: {}\".format(cp_2000_AmLi_dose_err*100))\n",
    "print(\"Cf: {}\".format(cp_2000_Cf_dose_err*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8664d24b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "088c2546",
   "metadata": {},
   "source": [
    "### Current results & future steps\n",
    "\n",
    "Prediction on the test data is approximately equivalently bad for all of these models. All models seem to have learned to predict significant values in at most 2 or 3 bins, likely as the vase majority of the sources used for training only have counts in at most 3 bins. A way of tackling this would be to augment the training dataset with sources that are continuous across more bins than the existing data points, which could be accomplished in several ways:\n",
    "\n",
    "* Generating additional training data with a greater spread in energy (e.g. larger Gaussian spread), such that individual data points cover more energy bins\n",
    "* Implementing a transform to produce new data points composed of a linear combination of two or more existing data points\n",
    "* Training on 1 or 2 of the test sources, to see if that improves prediction on the third (and on more complex sources in general) \n",
    "\n",
    "Whilst the first approach is straightforward, it will add data points that peak around a particular bin and have a spread around that bin, rather than producing a more complex neutron spectrum that may have multiple peaks, although more complex distributions than a Gaussian could be used. It also would require generating a significant amount of additional training data, which is not storage efficient.\n",
    "\n",
    "The second approach can in principle can teach the model more flexibility in how sources with a wide range of energies are encoded in the counts measured by the detector. This transformation would allow the model to learn an how an arbitrary fluence is encoded in the inputs, but in order to result in good prediction on real sources it may require some more careful logic on which sources are combined by the transformation, e.g. only taking those close in energy. However, following implementation of a rotation transform it may be informative to provide training data that is a composite of a high energy source on one side of the detector with a thermal source on the opposite side, to emulate a scenario with backscattered thermal neutrons. \n",
    "\n",
    "Regarding the final approach eventually the model will be trained on all of these sources, but in the mean time training on one of these may be useful to test the ability of the model to learn a more continuous source on top of the monoenergetic sources it is already learning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe524592",
   "metadata": {},
   "source": [
    "The model also can regularly predicit negative values in energy bins, when obviously this is not a physical result. In order to prevent this, I propose adding a term to the loss that penalises any bins with a negative value in the output. This could for example be done with a simple boolean check on each value in the output tensor, adding a factor *k* to the loss for each bin that has a negative value. This factor *k* could be tuned at initialisation of the loss function in order to tune how harshly the model penalises negative bins, and the ideal value of this parameter can be investigated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c975e3",
   "metadata": {},
   "source": [
    "A final point of note is how many epochs the model takes to train - even after 2000 epochs the training and validation losses are still decreasing, along with the average absolute percentage error on dose. This motivates revisiting the optimisation of the network, particularly looking at the learning rate or a learning rate scheduler, as well as the choice of optimisation algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "id": "3d2d6adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_cubes_144,total_count_144,time_144 = NNPL.PrepareRealInput('/home/nr1315/Documents/Project/NPL_2021/vdg_1um_Li7target19A_433cm_0deg.h5')\n",
    "sdc_cubes_144,sdc_count_144,sdc_time_144 = NNPL.PrepareRealInput('/home/nr1315/Documents/Project/NPL_2021/vdg_1um_Li7target19A_433cm_0deg_shadowcone.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "3d8414d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_dose_144,true_count_144,true_count_err_144 = NNPL.CalcTrueDose(144e-3,'144 keV',time_144,dose_coeffs = '/home/nr1315/Documents/Project/effective_dose_coeffs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "id": "2fef39b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_cubes_144 = (total_count_144*real_cubes_144/time_144 - sdc_count_144*sdc_cubes_144/sdc_time_144)*min(time_144,sdc_time_144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657fa292",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "id": "9df73371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalcDoseNPL2021(dfile,source_dist,dose_curve,model,bins,sdc=None,source_bins = None):\n",
    "    real_cubes,total_count,real_time = NNPL.PrepareRealInput(dfile)\n",
    "    \n",
    "    if sdc is not None:\n",
    "        sdc_cubes,sdc_count,sdc_time = NNPL.PrepareRealInput(sdc)\n",
    "\n",
    "        sub_cubes = (total_count*real_cubes/real_time - sdc_count*sdc_cubes/sdc_time)*min(real_time,sdc_time)\n",
    "        sub_cubes = sub_cubes/sub_cubes.sum()\n",
    "    else:\n",
    "        sub_cubes = real_cubes\n",
    "    \n",
    "    pred_fluence = model(torch.from_numpy(sub_cubes).to(torch.float)).detach().numpy()\n",
    "    \n",
    "    integrated_dose_bins = []\n",
    "    for i in range(len(bins)-1):\n",
    "        integrated_dose = quad(dose_curve,bins[i],bins[i+1],limit=200)[0]\n",
    "        integrated_dose_bins.append(integrated_dose)\n",
    "    integrated_dose_bins = np.array(integrated_dose_bins)/np.diff(bins)\n",
    "    \n",
    "    pred_dose = (pred_fluence * integrated_dose_bins).sum()\n",
    "    \n",
    "    if callable(source_dist):\n",
    "        true_dose = quad(lambda x:source_dist(x)*dose_curve(x),0,np.inf,limit=200)[0]\n",
    "    else:\n",
    "        true_dose = dose_curve(source_dist)\n",
    "        \n",
    "    if source_bins is not None:\n",
    "        binned_dose = (integrated_dose_bins * source_bins).sum()\n",
    "        \n",
    "        return true_dose,binned_dose,pred_dose\n",
    "    \n",
    "    else:\n",
    "        return true_dose,pred_dose\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "id": "6186ed00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(58.356), 73.31749652179467, 186.03095087034413)"
      ]
     },
     "execution_count": 673,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CalcDoseNPL2021('/home/nr1315/Documents/Project/NPL_2021/vdg_1um_Li7target19A_433cm_0deg.h5',\n",
    "                144e-3,\n",
    "                ap_dose_curve,\n",
    "                model_cubes,\n",
    "                bins,\n",
    "                sdc = '/home/nr1315/Documents/Project/NPL_2021/vdg_1um_Li7target19A_433cm_0deg_shadowcone.h5',\n",
    "                source_bins = np.histogram(144e-3,bins=bins)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "id": "dd09874e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(58.356), 73.31749652179467, 264.9335371437561)"
      ]
     },
     "execution_count": 674,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CalcDoseNPL2021('/home/nr1315/Documents/Project/NPL_2021/vdg_1um_Li7target19A_433cm_0deg.h5',\n",
    "                144e-3,\n",
    "                ap_dose_curve,\n",
    "                model_cubes,\n",
    "                bins,\n",
    "                source_bins = np.histogram(144e-3,bins=bins)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72077b79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4edc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalcDosePerFluence(dose_curve,source_dist,bins,model,source_bins):\n",
    "    integrated_dose_bins = []\n",
    "    for i in range(len(bins)-1):\n",
    "        integrated_dose = quad(dose_curve,bins[i],bins[i+1],limit=200)[0]\n",
    "        integrated_dose_bins.append(integrated_dose)\n",
    "    integrated_dose_bins = np.array(integrated_dose_bins)/np.diff(bins)\n",
    "    \n",
    "    if callable(source_dist):\n",
    "        true_dose = quad(lambda x:source_dist(x)*dose_curve(x),0,np.inf,limit=200)[0]\n",
    "    else:\n",
    "        true_dose = dose_curve(source_dist)\n",
    "    \n",
    "    binned_dose = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9496a8cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "1d9c6df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22947/3126944317.py:3: IntegrationWarning: The occurrence of roundoff error is detected, which prevents \n",
      "  the requested tolerance from being achieved.  The error may be \n",
      "  underestimated.\n",
      "  Cftotal = quad(Cf,cfyield[0][0],cfyield[0][-1],limit=200)[0]\n"
     ]
    }
   ],
   "source": [
    "cfyield = np.load('/home/nr1315/Documents/Project/MachineLearning/Cf252Yield.npy')\n",
    "Cf = interp1d(cfyield[0],cfyield[1])\n",
    "Cftotal = quad(Cf,cfyield[0][0],cfyield[0][-1],limit=200)[0]\n",
    "Cf2 = interp1d(cfyield[0],cfyield[1]/Cftotal)#,bounds_error = False,fill_value = 0.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "3a2c2200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalcBinningDoseErr(source,coeffs,d,limits,target,energy_bin_centres):\n",
    "    dose_curve = interp1d(coeffs['Energy / MeV'],coeffs[d],bounds_error = False,fill_value = 0)\n",
    "    energies = np.geomspace(limits[0],limits[1],100000)\n",
    "    dose_vals = dose_curve(energies)\n",
    "\n",
    "    if callable(source):\n",
    "        func_vals = source(energies)\n",
    "        integ_curve = interp1d(energies,func_vals*dose_vals/20**2,bounds_error = False,fill_value = 0)\n",
    "        true_dose_per_neutron = quad(integ_curve,energies[0],energies[-1],limit=200)[0]\n",
    "    else:\n",
    "        true_dose_per_neutron = dose_curve(source)/20**2\n",
    "        \n",
    "    binned_dose_per_neutron = (target/target.sum()*dose_curve(energy_bin_centres)/20**2).sum()\n",
    "    \n",
    "    percentage_binning_dose_error = 100*(binned_dose_per_neutron - true_dose_per_neutron)/true_dose_per_neutron\n",
    "    \n",
    "    return true_dose_per_neutron,binned_dose_per_neutron,percentage_binning_dose_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "2030dec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrepareYieldDist(yield_file):\n",
    "    source_yield = np.load(yield_file)\n",
    "    source_dist = interp1d(source_yield[0],source_yield[1])\n",
    "    source_total = quad(source_dist,source_yield[0][0],source_yield[0][-1],limit=200)[0]\n",
    "    source_dist_norm = interp1d(source_yield[0],source_yield[1]/source_total,bounds_error = False,fill_value = 0)\n",
    "    \n",
    "    return source_dist_norm,(source_yield[0][0],source_yield[0][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be239415",
   "metadata": {},
   "outputs": [],
   "source": [
    "AmLi,AmLi_bounds = NNPL.PrepareYieldDist('/home/nr1315/Documents/Project/MachineLearning/AmLiYield.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "9ec75ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nr1315/Documents/Project/Analysis/AnalysisRepo/NNPytorchLightning.py:441: IntegrationWarning: The occurrence of roundoff error is detected, which prevents \n",
      "  the requested tolerance from being achieved.  The error may be \n",
      "  underestimated.\n",
      "  true_dose_per_neutron = quad(integ_curve,energies[0],energies[-1],limit=200)[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.43852272942531234, 0.451494915546875, 2.9581559292406125)"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NNPL.CalcBinningDoseErr(AmLi,dc,'AP',list(AmLi_bounds),np.load('/home/nr1315/Documents/Project/MachineLearning/TestingData/SimEnergyBins_AmLi.npy'),centres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "92ba2484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.01885, 0.18585249999999998, 885.9549071618036)"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NNPL.CalcBinningDoseErr(bins[1],dc,'AP',[energies[0],energies[-1]],np.histogram(bins[1],bins=bins)[0],centres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "f3438cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.load(energy_bins)\n",
    "centres = bins[:-1] + np.diff(bins)/2\n",
    "plt.bar(centres,model_cubes(torch.from_numpy(real_cubes_144).to(torch.float)).detach().numpy(),width=np.diff(bins),edgecolor='black')\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ded0326",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = pd.read_hdf(coeffs)\n",
    "\n",
    "bins = np.load(energy_bins)\n",
    "centres = bins[:-1] + np.diff(bins)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b801218",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "ap_dose_curve = interp1d(dc['Energy / MeV'],dc['AP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ada71c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dose_curve(d,ax):\n",
    "    energies = dc['Energy / MeV']\n",
    "    dose_curve = interp1d(energies,dc[d])\n",
    "    dose_vals = dose_curve(energies)\n",
    "\n",
    "    ax.plot(energies,dose_vals)\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlabel('Energy / MeV',fontsize=24)\n",
    "    ax.set_ylabel('Effective dose / pSv cm$^{2}$',fontsize=24)\n",
    "    ax.set_title(d,fontsize=32)\n",
    "    \n",
    "    return dose_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aff50d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "ap_dose_curve = plot_dose_curve('AP',ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5698fc0d",
   "metadata": {},
   "source": [
    "For comparison, here is the AP dose curve:\n",
    "\n",
    "![AP dose curve](Plots/AP_dose_curve.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "baeb7773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<scipy.interpolate.interpolate.interp1d at 0x7ff7e85ca180>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.integrate import quad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b191f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32524/3034381115.py:4: IntegrationWarning: The occurrence of roundoff error is detected, which prevents \n",
      "  the requested tolerance from being achieved.  The error may be \n",
      "  underestimated.\n",
      "  bin_dose_integral,bin_dose_integral_err = quad(ap_dose_curve,bins[i],bins[i+1],limit=200)\n"
     ]
    }
   ],
   "source": [
    "dose_integrals = []\n",
    "dose_integral_errs = []\n",
    "for i in range(8):\n",
    "    bin_dose_integral,bin_dose_integral_err = quad(ap_dose_curve,bins[i],bins[i+1],limit=200)\n",
    "    dose_integrals.append(bin_dose_integral)\n",
    "    dose_integral_errs.append(bin_dose_integral_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7ab50501",
   "metadata": {},
   "outputs": [],
   "source": [
    "integral_bin_dose = np.array(dose_integrals)/np.diff(bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1c8510e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "centre_bin_dose = ap_dose_curve(centres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0d5ca19a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00110829, 0.01376769, 0.00537634, 0.0141423 , 0.01158265,\n",
       "       0.00529191, 0.00350019, 0.00052843])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs((centre_bin_dose - integral_bin_dose)/centre_bin_dose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "264c3046",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_energy_err = centres-bins[:-1]\n",
    "upper_energy_err = bins[1:] - centres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "da6b1546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.499995e-04, 1.872500e-01, 2.000000e-01, 3.625000e-01,\n",
       "        1.125000e+00, 3.125000e+00, 1.100000e+01, 3.400000e+01]),\n",
       " array([2.499995e-04, 1.872500e-01, 2.000000e-01, 3.625000e-01,\n",
       "        1.125000e+00, 3.125000e+00, 1.100000e+01, 3.400000e+01]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower_energy_err,upper_energy_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "90358db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_edges = np.vstack([bins[:-1],bins[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4b778481",
   "metadata": {},
   "outputs": [],
   "source": [
    "dose_per_fluence_at_edges = ap_dose_curve(bin_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0dc35ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dose_per_neutron_at_edges = dose_per_fluence_at_edges/20**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d8a75181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.007725 , 0.01885  , 0.3440625, 0.6240625, 0.9125   , 1.191875 ,\n",
       "        1.25     , 1.1275   ],\n",
       "       [0.01885  , 0.3440625, 0.6240625, 0.9125   , 1.191875 , 1.25     ,\n",
       "        1.1275   , 1.005    ]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dose_per_neutron_at_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8e841e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0192245 , 0.18329374, 0.49140625, 0.79099677, 1.08447917,\n",
       "       1.2405875 , 1.18914773, 1.06226103])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integral_bin_dose/20**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "77b7da70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Effective dose per neutron / pSv')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(centres,integral_bin_dose/20**2)\n",
    "plt.errorbar(centres,integral_bin_dose/20**2,yerr = [integral_bin_dose/20**2 - dose_per_neutron_at_edges[0],dose_per_neutron_at_edges[1]-integral_bin_dose/20**2],fmt='o',capsize=3)\n",
    "plt.xlabel('Energy / MeV',fontsize=24)\n",
    "plt.xscale('log')\n",
    "plt.ylabel('Effective dose per neutron / pSv',fontsize=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d80382",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "31a3a9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfyield = np.load('/home/nr1315/Documents/Project/MachineLearning/Cf252Yield.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cc5b9d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32524/1898761304.py:2: IntegrationWarning: The occurrence of roundoff error is detected, which prevents \n",
      "  the requested tolerance from being achieved.  The error may be \n",
      "  underestimated.\n",
      "  cf_total = quad(cf_dist,energies[0],energies[-1],limit=200)[0]\n"
     ]
    }
   ],
   "source": [
    "cf_dist = interp1d(cfyield[0],cfyield[1],bounds_error = False,fill_value=0.)\n",
    "cf_total = quad(cf_dist,energies[0],energies[-1],limit=200)[0]\n",
    "Cf = interp1d(cfyield[0],cfyield[1]/cf_total,bounds_error = False,fill_value=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d0f330df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6730263732315502"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Cf(centres)*ap_dose_curve(centres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e20e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cf(energy)*ap_dose_curve(energies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "77fe963f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cf(energies)*ap_dose_curve(energies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "54b5b4e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01011893, 0.24707707, 0.33394158, 0.3178533 , 0.17256136,\n",
       "       0.01408293, 0.        , 0.        ])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cf(centres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "fa49c8cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7ff7e35f27c0>"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(centres,Cf(centres)*integral_bin_dose/20**2,label='Binned Cf dose values',color='blue')\n",
    "plt.plot(energies,Cf(energies)*ap_dose_curve(energies)/20**2,label='Cf true dose values',color='red')\n",
    "#plt.scatter(144e-3,ap_dose_curve(144e-3)/20**2,label='True 144 keV',color='red')\n",
    "plt.errorbar(centres,Cf(centres)*integral_bin_dose/20**2,yerr = [Cf(centres)*(integral_bin_dose/20**2 - dose_per_neutron_at_edges[0]),Cf(centres)*(dose_per_neutron_at_edges[1]-integral_bin_dose/20**2)],fmt='o',capsize=3,color='blue')\n",
    "\n",
    "plt.fill_between(centres,Cf(centres)*dose_per_neutron_at_edges[0],Cf(centres)*dose_per_neutron_at_edges[1],alpha=0.3)\n",
    "\n",
    "plt.xlabel('Energy / MeV',fontsize=24)\n",
    "plt.xscale('log')\n",
    "plt.ylabel('Effective dose per neutron / pSv',fontsize=24)\n",
    "plt.legend(loc='upper left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "099fe3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32524/2878908818.py:3: IntegrationWarning: The occurrence of roundoff error is detected, which prevents \n",
      "  the requested tolerance from being achieved.  The error may be \n",
      "  underestimated.\n",
      "  dose = quad(lambda x: Cf(x)*ap_dose_curve(x),bins[i],bins[i+1],limit=200)[0]\n"
     ]
    }
   ],
   "source": [
    "true_cf_dose_per_bin=[]\n",
    "for i in range(8):\n",
    "    dose = quad(lambda x: Cf(x)*ap_dose_curve(x),bins[i],bins[i+1],limit=200)[0]\n",
    "    true_cf_dose_per_bin.append(dose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "2a3b58be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.655549020231811e-05,\n",
       " 7.197645904088434,\n",
       " 26.012700583733448,\n",
       " 72.02507234214457,\n",
       " 169.85867711753284,\n",
       " 74.14979519925443,\n",
       " 1.119350203844603,\n",
       " 0.0]"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_cf_dose_per_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "53d3c3c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.78125724e-02, 1.81150722e+01, 6.56403916e+01, 1.00568372e+02,\n",
       "       7.48556800e+01, 6.98844468e+00, 0.00000000e+00, 0.00000000e+00])"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integral_bin_dose*Cf(centres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "d20dcd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_bins = np.load('/home/nr1315/Documents/Project/MachineLearning/TestingData/SimEnergyBins_Cf252.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "80e179a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.08459375, 0.1333125 , 0.22817187, 0.39896875,\n",
       "       0.152625  , 0.00232812, 0.        ])"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_bins/cf_bins.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "87452597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01011893, 0.24707707, 0.33394158, 0.3178533 , 0.17256136,\n",
       "       0.01408293, 0.        , 0.        ])"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cf(centres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "9f5f9e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "E,Yield = cfyield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "f9fee43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = interp1d(E,Yield,bounds_error = False,fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "974b6fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32524/3828999008.py:1: IntegrationWarning: The occurrence of roundoff error is detected, which prevents \n",
      "  the requested tolerance from being achieved.  The error may be \n",
      "  underestimated.\n",
      "  norm = quad(dist,min(E),max(E),limit=200)[0]\n"
     ]
    }
   ],
   "source": [
    "norm = quad(dist,min(E),max(E),limit=200)[0]\n",
    "dist2 = interp1d(E,np.array(Yield)/norm,bounds_error=False,fill_value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "4a991b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff7e1a9ba90>]"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.bar(centres,cf_bins/max(cf_bins),width=np.diff(bins),edgecolor='black',alpha=0.3)\n",
    "#plt.plot(energies,Cf(energies),color='red')\n",
    "plt.plot(cfyield[0],cfyield[1]/max(cfyield[1]),color='green')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "2a0cf120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.        ,   6.20220197,  26.20423828,  72.19328625,\n",
       "       173.06931901,  75.73786686,   1.10739382,   0.        ])"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integral_bin_dose*cf_bins/cf_bins.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "4e73a58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32524/730856803.py:1: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.abs(((integral_bin_dose*Cf(centres)) - true_cf_dose_per_bin)/true_cf_dose_per_bin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2.12761521e+03, 1.51680513e+00, 1.52339781e+00, 3.96296713e-01,\n",
       "       5.59306117e-01, 9.05752340e-01, 1.00000000e+00,            nan])"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(((integral_bin_dose*Cf(centres)) - true_cf_dose_per_bin)/true_cf_dose_per_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd55e8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5719eceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6b6d1145",
   "metadata": {},
   "outputs": [],
   "source": [
    "minima = []\n",
    "for i in range(8):\n",
    "    local_minimum = optimize.fminbound(ap_dose_curve,bins[i],bins[i+1])\n",
    "    minima.append(local_minimum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5fb3fcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxima = []\n",
    "for i in range(8):\n",
    "    local_maximum = optimize.fminbound(lambda x: -1*ap_dose_curve(x),bins[i],bins[i+1])\n",
    "    maxima.append(local_maximum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "2650a0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7ff7e6af07f0>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(energies,ap_dose_curve(energies))\n",
    "plt.xscale('log')\n",
    "plt.bar(centres,np.repeat(500,len(centres)),width=np.diff(bins),edgecolor='black',alpha=0.1,color='red')\n",
    "#plt.scatter(minima,ap_dose_curve(minima),label='Minima',alpha=0.6,s=7)\n",
    "#plt.scatter(maxima,ap_dose_curve(maxima),label='Maxima',alpha=0.6,s=7)\n",
    "plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "7443ce8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "minima_points = np.repeat(ap_dose_curve(minima)/integral_bin_dose,2)\n",
    "maxima_points = np.repeat(ap_dose_curve(maxima)/integral_bin_dose,2)\n",
    "edges = np.sort(np.concatenate([bins[:-1],bins[1:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "c0366a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(energies,np.repeat(1,len(energies)),color='blue')\n",
    "#plt.plot(energies,Cf(energies)*ap_dose_curve(energies)/20**2,label='Cf true dose values',color='red')\n",
    "#plt.scatter(144e-3,ap_dose_curve(144e-3)/20**2,label='True 144 keV',color='red')\n",
    "#plt.errorbar(centres,integral_bin_dose/integral_bin_dose,yerr = [(integral_bin_dose - ap_dose_curve(minima))/integral_bin_dose,(ap_dose_curve(maxima)-integral_bin_dose)/integral_bin_dose],fmt='o',capsize=30,color='blue')\n",
    "#plt.bar(centres,np.repeat(1.5,len(centres)),width=np.diff(bins),edgecolor='black',alpha=0.1,color='red')\n",
    "#plt.plot(energies,ap_dose_curve(energies),label='AP effective dose',color='red')\n",
    "\n",
    "plt.plot(edges,minima_points,color='green',label ='Lower bound')\n",
    "plt.plot(edges,maxima_points,color='purple',label='Upper bound')\n",
    "\n",
    "#for i in range(8):\n",
    "#    rect = mpatches.Rectangle((bins[i],0.9*min(ap_dose_curve(minima)/integral_bin_dose)),np.diff(bins)[i],1.1*max(ap_dose_curve(maxima)/integral_bin_dose) - 0.9*min(ap_dose_curve(minima)/integral_bin_dose),alpha=0.1,color='red')\n",
    " #   plt.gca().add_patch(rect)\n",
    "    \n",
    "#plt.scatter(144e-3,ap_dose_curve(144e-3),label='144 keV',color='green')\n",
    "#plt.scatter(1.2,ap_dose_curve(1.2),label='1.2 MeV',color='purple')\n",
    "\n",
    "#plt.fill_between(centres,ap_dose_curve(minima)/integral_bin_dose,ap_dose_curve(maxima)/integral_bin_dose,alpha=0.3)\n",
    "#plt.plot(centres,ap_dose_curve(minima)/integral_bin_dose)\n",
    "#plt.plot(centres,ap_dose_curve(maxima)/integral_bin_dose)\n",
    "\n",
    "\n",
    "#for i in range(8):\n",
    "#    plt.fill_between([bins[i],bins[i+1]],np.repeat(ap_dose_curve(minima[i])/integral_bin_dose[i],2),np.repeat(ap_dose_curve(maxima[i])/integral_bin_dose[i],2),alpha=0.3,color='blue')\n",
    "#    plt.plot([bins[i],bins[i+1]],np.repeat(ap_dose_curve(minima[i])/integral_bin_dose[i],2),c='r')\n",
    "#    plt.plot([bins[i],bins[i+1]],np.repeat(ap_dose_curve(maxima[i])/integral_bin_dose[i],2),c='g')\n",
    "\n",
    "plt.xlabel('Energy / MeV',fontsize=24)\n",
    "plt.xscale('log')\n",
    "plt.ylabel('Relative uncertainty on effective dose per fluence',fontsize=24)\n",
    "plt.title('')\n",
    "plt.legend(loc='upper left',fontsize=18)\n",
    "plt.xlim(energies[0],energies[-1])\n",
    "\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.title('Relative uncertainty on binned dose',fontsize=32)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "e4b2b4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_dose_err(energy,int_bin_dose):\n",
    "    minimum = energy>=bins[0]\n",
    "    maximum = energy<=bins[1]\n",
    "    for i in range(1,8):\n",
    "        minimum = np.vstack([minimum,energy>=bins[i]])\n",
    "        maximum = np.vstack([maximum,energy<=bins[i+1]])\n",
    "    in_bin = minimum&maximum\n",
    "    on_boundary = np.where(in_bin.sum(axis=0)==2)[0]\n",
    "    in_bin[np.nonzero(in_bin[:,on_boundary])[0][0]+1:,on_boundary]=False\n",
    "        \n",
    "    bin_dose = int_bin_dose[np.where(in_bin)[0]]\n",
    "    true_dose = ap_dose_curve(energy)\n",
    "    dose_err = (bin_dose - true_dose)/true_dose\n",
    "    return dose_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "90caffda",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.array(draws).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "b96d69c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist,b = np.histogram(d,bins=bins)\n",
    "\n",
    "plt.bar(centres,hist/hist.max(),width=np.diff(bins),edgecolor='black',alpha=0.3)\n",
    "plt.plot(cfyield[0],cfyield[1]/cfyield[1].max())\n",
    "plt.plot(3*cfyield[0],cdist.pdf(cfyield[0])/max(cdist.pdf(cfyield[0])))\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "fd830332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.YTick at 0x7ff7e1a33550>,\n",
       "  <matplotlib.axis.YTick at 0x7ff7e1a3dd90>,\n",
       "  <matplotlib.axis.YTick at 0x7ff7e1a3d460>,\n",
       "  <matplotlib.axis.YTick at 0x7ff7e19ee790>,\n",
       "  <matplotlib.axis.YTick at 0x7ff7e19f6520>,\n",
       "  <matplotlib.axis.YTick at 0x7ff7e19f6c70>,\n",
       "  <matplotlib.axis.YTick at 0x7ff7e19f7400>,\n",
       "  <matplotlib.axis.YTick at 0x7ff7e19f7b50>,\n",
       "  <matplotlib.axis.YTick at 0x7ff7e19f78e0>,\n",
       "  <matplotlib.axis.YTick at 0x7ff7e19f65e0>,\n",
       "  <matplotlib.axis.YTick at 0x7ff7e19ff1c0>,\n",
       "  <matplotlib.axis.YTick at 0x7ff7e19ff7f0>,\n",
       "  <matplotlib.axis.YTick at 0x7ff7e1a040a0>,\n",
       "  <matplotlib.axis.YTick at 0x7ff7e1a046d0>,\n",
       "  <matplotlib.axis.YTick at 0x7ff7e1a04e20>,\n",
       "  <matplotlib.axis.YTick at 0x7ff7e1a04970>,\n",
       "  <matplotlib.axis.YTick at 0x7ff7e19ff580>,\n",
       "  <matplotlib.axis.YTick at 0x7ff7e1a0b370>,\n",
       "  <matplotlib.axis.YTick at 0x7ff7e1a0b9a0>,\n",
       "  <matplotlib.axis.YTick at 0x7ff7e1a13130>,\n",
       "  <matplotlib.axis.YTick at 0x7ff7e1a13880>],\n",
       " [Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, '')])"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dose_err = 100*bin_dose_err(energies,integral_bin_dose)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.plot(energies,dose_err)\n",
    "#plt.plot(energies,bin_dose_err(energies,np.array(minima)),label='Minima')\n",
    "#plt.plot(energies,bin_dose_err(energies,np.array(maxima)),label='Maxima')\n",
    "ax.set_xscale('log')\n",
    "#plt.legend(loc='upper left')\n",
    "ax.grid(axis='y')\n",
    "\n",
    "for i in range(8):\n",
    "    rect = mpatches.Rectangle((bins[i],np.floor(min(dose_err)/100)*100),np.diff(bins)[i],1.2*max(dose_err) - 0.9*min(dose_err),alpha=0.1,color='red')\n",
    "    plt.gca().add_patch(rect)\n",
    "\n",
    "\n",
    "ax.set_title('Relative error from estimating using averaged bin dose, AP',fontsize=32)\n",
    "ax.set_xlabel('Energy / MeV',fontsize=24)\n",
    "ax.set_ylabel('Relative error / %',fontsize=24)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(np.arange(np.floor(min(dose_err)/100)*100,np.ceil(max(dose_err)/100)*100+25,50),fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e6621d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a617861",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "482173ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "001bb99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = norm(450e-3,100e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "0bbdc4cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff7e1930430>]"
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(energies,dist.pdf(energies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "54c2adc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "2acac935",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = np.histogram(np.random.normal(450e-3,100e-3,10000),bins=bins)[0]\n",
    "h = h/h.sum()\n",
    "\n",
    "binned_450_gauss_dose = integral_bin_dose*h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "76561eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "energies_dose = ap_dose_curve(energies)*dist.pdf(energies)\n",
    "minimum = energies>=bins[0]\n",
    "maximum = energies<=bins[1]\n",
    "for i in range(1,8):\n",
    "    minimum = np.vstack([minimum,energies>=bins[i]])\n",
    "    maximum = np.vstack([maximum,energies<=bins[i+1]])\n",
    "in_bin = minimum&maximum\n",
    "on_boundary = np.where(in_bin.sum(axis=0)==2)[0]\n",
    "in_bin[np.nonzero(in_bin[:,on_boundary])[0][0]+1:,on_boundary]=False\n",
    "\n",
    "binned_true_dose = []\n",
    "for i in range(8):\n",
    "    binned_true_dose.append(`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "d01e72ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_true_dose=[]\n",
    "for i in range(8):\n",
    "    dose = quad(lambda x:ap_dose_curve(x)*dist.pdf(x),bins[i],bins[i+1],limit=200)[0]\n",
    "    binned_true_dose.append(dose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "a51ff09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_dose_total = quad(lambda x:ap_dose_curve(x)*dist.pdf(x),bins[0],bins[-1],limit=200)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "id": "afe28325",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_dose_error(dose_curve,bins,source_dist,bin_counts,points=None):\n",
    "    integral_bin_doses = []\n",
    "    for i in range(len(bins)-1):\n",
    "        bin_dose = quad(dose_curve,bins[i],bins[i+1],limit=200)[0]\n",
    "        integral_bin_doses.append(bin_dose)\n",
    "    integral_bin_doses = np.array(integral_bin_doses)/np.diff(bins)\n",
    "    binned_source_dose = (bin_counts * integral_bin_doses).sum()\n",
    "    \n",
    "    true_dose = quad(lambda x : dose_curve(x)*source_dist(x),bins[0],bins[-1],limit=200,points=points)[0]\n",
    "    \n",
    "    relative_dose_err = (binned_source_dose - true_dose)/true_dose\n",
    "    \n",
    "    return binned_source_dose,true_dose,relative_dose_err\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "95cf25e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32524/202615497.py:4: IntegrationWarning: The occurrence of roundoff error is detected, which prevents \n",
      "  the requested tolerance from being achieved.  The error may be \n",
      "  underestimated.\n",
      "  bin_dose = quad(dose_curve,bins[i],bins[i+1],limit=200)[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(168.5225573105213, 160.33957697668237, 0.05103531198057834)"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_dose_error(ap_dose_curve,bins,dist.pdf,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "id": "c42262f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_Cf_dose,true_Cf_dose,Cf_dose_error = bin_dose_error(ap_dose_curve,bins,Cf,cf_bins/cf_bins.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "70798b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "AmLi,AmLi_bounds = NNPL.PrepareYieldDist('/home/nr1315/Documents/Project/MachineLearning/AmLiYield.npy')\n",
    "AmLi_counts = np.load('/home/nr1315/Documents/Project/MachineLearning/TestingData/SimEnergyBins_AmLi.npy')\n",
    "AmLi_counts = AmLi_counts/AmLi_counts.sum()\n",
    "\n",
    "binned_AmLi_dose,true_AmLi_dose,AmLi_dose_error = bin_dose_error(ap_dose_curve,bins,AmLi,AmLi_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "01182619",
   "metadata": {},
   "outputs": [],
   "source": [
    "AmBe,AmBe_bounds = NNPL.PrepareYieldDist('/home/nr1315/Documents/Project/MachineLearning/AmBeYield.npy')\n",
    "AmBe_counts = np.load('/home/nr1315/Documents/Project/MachineLearning/TestingData/SimEnergyBins_AmBe.npy')\n",
    "AmBe_counts = AmBe_counts/AmBe_counts.sum()\n",
    "\n",
    "binned_AmBe_dose,true_AmBe_dose,AmBe_dose_error = bin_dose_error(ap_dose_curve,bins,AmBe,AmBe_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "ce6d3a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "mono_gauss_144 = norm(144e-3,1e-6)\n",
    "points = [143e-3,145e-3]\n",
    "binned_144keV_dose,true_144keV_dose,mono_144keV_dose_error = bin_dose_error(ap_dose_curve,bins,mono_gauss_144.pdf,np.histogram(144e-3,bins)[0],points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "3e2afabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mono_gauss_1_2 = norm(1.2,1e-6)\n",
    "points = [1.199,1.201]\n",
    "binned_1_2MeV_dose,true_1_2MeV_dose,mono_1_2MeV_dose_error = bin_dose_error(ap_dose_curve,bins,mono_gauss_1_2.pdf,np.histogram(1.2,bins)[0],points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "7077df9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cf dose error: 1.2\n",
      "AmBe dose error: -0.3\n",
      "AmLi dose error: 1.9\n",
      "144 keV dose error: 25.6\n",
      "1.2 MeV dose error: -4.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Cf dose error: {}\".format(np.round(100*Cf_dose_error,1)))\n",
    "print(\"AmBe dose error: {}\".format(np.round(100*AmBe_dose_error,1)))\n",
    "print(\"AmLi dose error: {}\".format(np.round(100*AmLi_dose_error,1)))\n",
    "print(\"144 keV dose error: {}\".format(np.round(100*mono_144keV_dose_error,1)))\n",
    "print(\"1.2 MeV dose error: {}\".format(np.round(100*mono_1_2MeV_dose_error,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239692cd",
   "metadata": {},
   "source": [
    "When calculating the dose from a binned fluence, the exact energies of the neutrons are not known and so instead dose must be calculated from an average dose per fluence for each bin. This average dose per fluence in each bin is found by integrating the dose coefficient curve over each bin and dividing by the bin width. Then, the total binned dose per fluence for each source is found by multiplying the counts in each bin for that source by the binned dose coefficients, and summing these products. This can be expressed as\n",
    "\n",
    "$$D_{binned} = \\sum_i c_i \\frac{\\int_i D(E) dE}{\\Delta E_i}, $$\n",
    "where c_i denotes the count in bin *i*, D(E) denotes the dose coefficients as a function of energy, and $\\Delta E_i$ denotes the width in energy of bin *i*. For dose per fluence, these counts $c_i$ should be normalised such that $\\sum_i c_i = 1$. \n",
    "\n",
    "The true dose per fluence is found by integrating the product of the dose curve and the source distribution over the total energy range, given as\n",
    "\n",
    "$$D_{true} = \\int_0^\\infty f(E) D(E) dE, $$\n",
    "where f(E) is the true source distribution as a function of energy. This distribution is normalised such that $\\int_0^\\infty f(E) dE = 1.$ \n",
    "\n",
    "Finally, the relative dose per fluence error is expressed as $\\frac{D_{binned} - D_{true}}{D_{true}}$. This relative error resulting from the binning is shown in the table below.\n",
    "\n",
    "| Source | Relative binning error |\n",
    "|--------|------------------------|\n",
    "| Cf-252 |          1.2%          |\n",
    "|  AmBe  |         -0.3%          |\n",
    "|  AmLi  |          1.9%          |\n",
    "|144 keV |         25.6%          |\n",
    "|1.2 MeV |         -4.1%          |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711dfdcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
