{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd6f36b0",
   "metadata": {},
   "source": [
    "# Neural network for dose measurement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fef0e9b",
   "metadata": {},
   "source": [
    "### Introduction and motivation\n",
    "In modern dosimetry, the gold standard of radiation dose measurement is _effective dose_. This quantity is defined as a sum over dose to each major organ in the human body, weighted by a set of _tissue weighting factors_ that encode the average risk to health of a dose to that organ. This is a complex and difficult measurement to make, as many modern dosimeters are either optimised for field direction measurement or a fluence measurement. For example, for a Bonner sphere spectrometer, measuring effective dose is a time-consuming and computationally intensive process that requires careful measurement of the radiation field with varying size of polyethylene sphere and a complex unfolding algorithm to reconstruct the fluence, and this still lacks directional information about the field. \n",
    "\n",
    "In contrast, the segmentation of nFacet 3D encodes both the direction and the energy of an incident neutron field. This can be visualised through the direction and intensity of attenuation of neutron count in the detector cubes. There are therefore two components to measuring the effective dose: reconstructing the fluence of the incident neutron field, and the direction of incidence of the neutrons. Here I focus on the fluence reconstruction using an artificial neural network (ANN), as once trained this is a fast method for reconstructing the fluence without need for a complex unfolding algorithm. \n",
    "\n",
    "### Neural network architecture\n",
    "\n",
    "The information for the network to learn is encoded in the distribution of neutron count across cubes in the detector. As a result, the first choice of input into the network consisted of 64 input neurons corresponding to the 64 cubes of the detector, whilst the output of the ANN was the binned fluence of the source. Additionally, summing the counts in planes of cubes provides additional information about the bulk response of the detector to the applied field and thus encodes more detailed information about the energy of the incident neutrons. This can be added to the inputs, adding 12 additional neurons corresponding to the four planes in the x, y and z directions. The model has subsequently been trained with and without these additional inputs to evaluate performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e8ed1d",
   "metadata": {},
   "source": [
    "### Fluence binning scheme\n",
    "\n",
    "TO BE ADDED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d031b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib tk\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import NNPytorchLightning as NNPL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a04e66",
   "metadata": {},
   "source": [
    "Here loading trained models to compare the training and validation losses per model, and look at performance on unseen data. These models are as follows:\n",
    "\n",
    "model_cubes: trained just on cube counts, with a batch size of 200 and 200 samples per data set, learning rate of 1e-3, for 500 epochs (for time)\n",
    "\n",
    "model_cubes_profiles: trained on cube counts and profiles, with a batch size of 200 and 200 samples per data set, learning rate of 1e-3, for 500 epochs (for time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a47ea1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = '/home/nr1315/Documents/Project/effective_dose_coeffs.h5'\n",
    "energy_bins = '/home/nr1315/Documents/Project/MachineLearning/energy_bins.npy'\n",
    "\n",
    "model_cubes = NNPL.LoadModel('/home/nr1315/Documents/Project/MachineLearning/lightning_logs/model_cubes_new_data/version_1/',torch.rand((1,1,64)),coeffs,energy_bins)\n",
    "\n",
    "model_cubes_profiles = NNPL.LoadModel('/home/nr1315/Documents/Project/MachineLearning/lightning_logs/model_cubes_profiles_new_data/version_5/',torch.rand((1,1,76)),coeffs,energy_bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bed94dd",
   "metadata": {},
   "source": [
    "Also need to load the loss curves separately, due to the way they are from the logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a405991",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cubes_tloss = pd.read_csv('/home/nr1315/Documents/Project/MachineLearning/LoggedParameters/run-model_cubes_new_data_version_1-tag-train_loss.csv')\n",
    "model_cubes_vloss = pd.read_csv('/home/nr1315/Documents/Project/MachineLearning/LoggedParameters/run-model_cubes_new_data_version_1-tag-val_loss.csv')\n",
    "model_cubes_dose_err = pd.read_csv('/home/nr1315/Documents/Project/MachineLearning/LoggedParameters/run-model_cubes_new_data_version_1-tag-dose_err_AP.csv')\n",
    "model_cubes_epoch = pd.read_csv('/home/nr1315/Documents/Project/MachineLearning/LoggedParameters/run-model_cubes_new_data_version_1-tag-epoch.csv')\n",
    "\n",
    "model_cubes_profiles_tloss = pd.read_csv('/home/nr1315/Documents/Project/MachineLearning/LoggedParameters/run-model_cubes_profiles_new_data_version_5-tag-train_loss.csv')\n",
    "model_cubes_profiles_vloss = pd.read_csv('/home/nr1315/Documents/Project/MachineLearning/LoggedParameters/run-model_cubes_profiles_new_data_version_5-tag-val_loss.csv')\n",
    "model_cubes_profiles_dose_err = pd.read_csv('/home/nr1315/Documents/Project/MachineLearning/LoggedParameters/run-model_cubes_profiles_new_data_version_5-tag-dose_err_AP.csv')\n",
    "model_cubes_profiles_epoch = pd.read_csv('/home/nr1315/Documents/Project/MachineLearning/LoggedParameters/run-model_cubes_profiles_new_data_version_5-tag-epoch.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9939c8bc",
   "metadata": {},
   "source": [
    "We also define the directories from which to load the testing data, for convenience:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "999beda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data_dir = '/home/nr1315/Documents/Project/MachineLearning/TestingData/'\n",
    "\n",
    "AmBe_counts = 'SimCubeCounts_AmBe_5_0-0-0-0-1-0_1500.npy'\n",
    "AmLi_counts = 'SimCubeCounts_AmLi_5_0-0-0-0-1-0_1500.npy'\n",
    "Cf_counts = 'SimCubeCounts_Cf252_6_0-0-0-0-1-0_1500.npy'\n",
    "\n",
    "AmBe_target = 'SimEnergyBins_AmBe.npy'\n",
    "AmLi_target = 'SimEnergyBins_AmLi.npy'\n",
    "Cf_target = 'SimEnergyBins_Cf252.npy'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9908db3",
   "metadata": {},
   "source": [
    "For each model in turn, we will look at the loss curves and prediction on AmBe, AmLi, and Cf-252. \n",
    "\n",
    "### Cubes only model, 500 epochs, 200 samples per dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f27b4824",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nr1315/miniconda3/envs/NewMLEnv/lib/python3.9/site-packages/scipy/interpolate/interpolate.py:623: RuntimeWarning: invalid value encountered in true_divide\n",
      "  slope = (y_hi - y_lo) / (x_hi - x_lo)[:, None]\n",
      "/home/nr1315/miniconda3/envs/NewMLEnv/lib/python3.9/site-packages/scipy/interpolate/interpolate.py:623: RuntimeWarning: invalid value encountered in true_divide\n",
      "  slope = (y_hi - y_lo) / (x_hi - x_lo)[:, None]\n"
     ]
    }
   ],
   "source": [
    "NNPL.PlotLosses([model_cubes_tloss,model_cubes_vloss],['Training loss','Validation loss'],'Cubes model, lr = 0.001, 200 samples per dataset',model_cubes_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc9e8c4",
   "metadata": {},
   "source": [
    "![Loss curves](Plots/model_cubes_loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1e4328",
   "metadata": {},
   "source": [
    "Here the model seems to be training well, although it does not appear to finish training after 500 epochs. \n",
    "\n",
    "It is also informative to look at the quality of model prediction on unseen data, in this case AmLi, AmBe, and Cf252 sources. These can be seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ce27fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,3,figsize=(30,10))\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "l1 = NNPL.compare_pred_true(model_cubes,testing_data_dir+AmBe_counts,testing_data_dir+AmBe_target,'AmBe','cubes only model',ax[0],24,np.load(energy_bins),1,loss_fn)\n",
    "l2 = NNPL.compare_pred_true(model_cubes,testing_data_dir+AmLi_counts,testing_data_dir+AmLi_target,'AmLi','cubes only model',ax[1],24,np.load(energy_bins),1,loss_fn)\n",
    "l3 = NNPL.compare_pred_true(model_cubes,testing_data_dir+Cf_counts,testing_data_dir+Cf_target,r'$^{252}$Cf','cubes only model',ax[2],24,np.load(energy_bins),1,loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238cd8d2",
   "metadata": {},
   "source": [
    "![Predictions of test data](Plots/model_cubes_prediction.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bcc7e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AmBe loss: 0.0878705158829689\n",
      "AmLi loss: 0.04326992481946945\n",
      "Cf-252 loss: 0.017681293189525604\n"
     ]
    }
   ],
   "source": [
    "print(\"AmBe loss: {}\".format(l1))\n",
    "print(\"AmLi loss: {}\".format(l2))\n",
    "print(\"Cf-252 loss: {}\".format(l3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fe0286",
   "metadata": {},
   "source": [
    "Whilst the model loss continues to decrease, the model still has poor performance on the unseen sources,  predicting negative values in at least half the bins in all three cases. It generally seems to predict the greatest count in the region around the average energy of each source, i.e. above, below and at 1 MeV for AmBe, AmLi and Cf respectively, as previous iterations of the model did. One possible way to combat this may be to introduce more complex sources into the training set, such as linear combinations of existing monoenergetics, to help the network learn how to better reconstruct a more complicated fluence.\n",
    "\n",
    "It is then informative to see the performance of the model on some of the validation data explicitly, as is shown below. The function used to plot this can be used to scroll through all of the training datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79942c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from NNPytorchLightning import FluenceReconDataset, Resample\n",
    "\n",
    "cubes_dataloader = torch.load('/home/nr1315/Documents/Project/MachineLearning/lightning_logs/model_cubes_new_data/version_1/val_dloader.pt')\n",
    "cubes_dataset,cubes_val_inds = cubes_dataloader.dataset.dataset,cubes_dataloader.dataset.indices\n",
    "\n",
    "check = NNPL.CheckTrainData(model_cubes,cubes_dataset,np.load(energy_bins))\n",
    "\n",
    "check.ViewTrainData()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548bce26",
   "metadata": {},
   "source": [
    "![550keV model cubes pred](Plots/model_cubes_550keV_pred.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f532f0",
   "metadata": {},
   "source": [
    "The model has generally performed well at predicting the bins for this validation data point with some count in an incorrect bin, but of note is that it is still predicting negative values in several bins. In order to avoid this, it may prove useful to add a term to the loss function that penalises any negative bins in the model prediction. \n",
    "\n",
    "A more thorough check of the validation data set for both this model and the following will be performed later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec887dc",
   "metadata": {},
   "source": [
    "### Cubes and profiles model, 200 samples per dataset, learning rate 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d33d5ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nr1315/miniconda3/envs/NewMLEnv/lib/python3.9/site-packages/scipy/interpolate/interpolate.py:623: RuntimeWarning: invalid value encountered in true_divide\n",
      "  slope = (y_hi - y_lo) / (x_hi - x_lo)[:, None]\n",
      "/home/nr1315/miniconda3/envs/NewMLEnv/lib/python3.9/site-packages/scipy/interpolate/interpolate.py:623: RuntimeWarning: invalid value encountered in true_divide\n",
      "  slope = (y_hi - y_lo) / (x_hi - x_lo)[:, None]\n"
     ]
    }
   ],
   "source": [
    "NNPL.PlotLosses([model_cubes_profiles_tloss,model_cubes_profiles_vloss],['Training loss','Validation loss'],'Cubes and profiles model, lr = 0.001, 200 samples per dataset',model_cubes_profiles_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c15676b",
   "metadata": {},
   "source": [
    "![losses](Plots/model_cubes_profiles_200samples.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0ee180",
   "metadata": {},
   "source": [
    "Whilst both the training loss and validation loss do both decrease, it is worth noting that the validation loss here is lower than the training loss, which in turn implies that the model needs to train for longer in this configuration. This is intuitive, as the increased number of bins due to the profile counts will mean there are a greater number of weights for the model to optimize. Other improvements may be found from increasing the learning rate or adding some learning rate scheduling, but otherwise training for longer is realistically required.\n",
    "\n",
    "It is also worthy of note that the loss is higher than for the cubes-only model, but this may be a factor of the incomplete training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c20cae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,3,figsize=(30,10))\n",
    "\n",
    "l4 = NNPL.compare_pred_true(model_cubes_profiles,testing_data_dir+'withProfiles/'+AmBe_counts,testing_data_dir+AmBe_target,'AmBe','cubes and \\n profiles model',ax[0],24,np.load(energy_bins),1,loss_fn)\n",
    "l5 = NNPL.compare_pred_true(model_cubes_profiles,testing_data_dir+'withProfiles/'+AmLi_counts,testing_data_dir+AmLi_target,'AmLi','cubes and \\n profiles model',ax[1],24,np.load(energy_bins),1,loss_fn)\n",
    "l6 = NNPL.compare_pred_true(model_cubes_profiles,testing_data_dir+'withProfiles/'+Cf_counts,testing_data_dir+Cf_target,r'$^{252}$Cf','cubes and \\n profiles model',ax[2],24,np.load(energy_bins),1,loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c48bee",
   "metadata": {},
   "source": [
    "![cubes profiles 200 samples prediction](Plots/model_cubes_profiles_200samples_prediction.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6c1b932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AmBe loss: 0.09213663637638092\n",
      "AmLi loss: 0.05291319638490677\n",
      "Cf-252 loss: 0.04942954331636429\n"
     ]
    }
   ],
   "source": [
    "print(\"AmBe loss: {}\".format(l4))\n",
    "print(\"AmLi loss: {}\".format(l5))\n",
    "print(\"Cf-252 loss: {}\".format(l6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba312d44",
   "metadata": {},
   "source": [
    "This model also performs poorly on the unseen data, although it has a lower loss than the cubes exclusive model. Most notably, this model predicts a large negative value in the first bin for all three sources, which further motivates introducing a penalty term to the loss to discourage any negative values in the model output. \n",
    "\n",
    "\n",
    "Validation data set checking needs some more work before conclusions can be drawn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "377b0678",
   "metadata": {},
   "outputs": [],
   "source": [
    "cubes_profiles_dataloader = torch.load('/home/nr1315/Documents/Project/MachineLearning/lightning_logs/model_cubes_profiles_new_data/version_5/val_dloader.pt')\n",
    "cubes_profiles_dataset,cubes_profiles_val_inds = cubes_profiles_dataloader.dataset.dataset,cubes_profiles_dataloader.dataset.indices\n",
    "\n",
    "check = NNPL.CheckTrainData(model_cubes_profiles,cubes_profiles_dataset,np.load(energy_bins))\n",
    "\n",
    "check.ViewTrainData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db3987e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "59f156f4",
   "metadata": {},
   "source": [
    "After these results both models were trained again for 2000 epochs, as it appeared that neither model had fully trained in the 500 epochs here. These models and the monitoring quantities are loaded in here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e4f67b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cubes_2000 = NNPL.LoadModel('/home/nr1315/Documents/Project/MachineLearning/lightning_logs/model_cubes_new_data/version_4/',torch.rand((1,1,64)),coeffs,energy_bins)\n",
    "\n",
    "model_cubes_profiles_2000 = NNPL.LoadModel('/home/nr1315/Documents/Project/MachineLearning/lightning_logs/model_cubes_profiles_new_data/version_11/',torch.rand((1,1,76)),coeffs,energy_bins)\n",
    "\n",
    "model_cubes_2000_tloss = pd.read_csv('/home/nr1315/Documents/Project/MachineLearning/LoggedParameters/run-model_cubes_new_data_version_4-tag-train_loss.csv')\n",
    "model_cubes_2000_vloss = pd.read_csv('/home/nr1315/Documents/Project/MachineLearning/LoggedParameters/run-model_cubes_new_data_version_4-tag-val_loss.csv')\n",
    "model_cubes_2000_dose_err = pd.read_csv('/home/nr1315/Documents/Project/MachineLearning/LoggedParameters/run-model_cubes_new_data_version_4-tag-dose_err_AP.csv')\n",
    "model_cubes_2000_epoch = pd.read_csv('/home/nr1315/Documents/Project/MachineLearning/LoggedParameters/run-model_cubes_new_data_version_4-tag-epoch.csv')\n",
    "\n",
    "model_cubes_profiles_2000_tloss = pd.read_csv('/home/nr1315/Documents/Project/MachineLearning/LoggedParameters/run-model_cubes_profiles_new_data_version_11-tag-train_loss.csv')\n",
    "model_cubes_profiles_2000_vloss = pd.read_csv('/home/nr1315/Documents/Project/MachineLearning/LoggedParameters/run-model_cubes_profiles_new_data_version_11-tag-val_loss.csv')\n",
    "model_cubes_profiles_2000_dose_err = pd.read_csv('/home/nr1315/Documents/Project/MachineLearning/LoggedParameters/run-model_cubes_profiles_new_data_version_11-tag-dose_err_AP.csv')\n",
    "\n",
    "model_cubes_profiles_2000_epoch = pd.read_csv('/home/nr1315/Documents/Project/MachineLearning/LoggedParameters/run-model_cubes_profiles_new_data_version_11-tag-epoch.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2309b8b",
   "metadata": {},
   "source": [
    "### Cubes model, learning rate 0.001, 200 samples per dataset, trained for 2000 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f4460ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "NNPL.PlotLosses([model_cubes_2000_tloss,model_cubes_2000_vloss],['Training loss','Validation loss'],'Cubes model, lr = 0.001, 200 samples per dataset, 2000 epochs',model_cubes_2000_epoch,log=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9c8994",
   "metadata": {},
   "source": [
    "![model cubes 2000epochs loss](Plots/model_cubes_2000_loss.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e5439960",
   "metadata": {},
   "outputs": [],
   "source": [
    "NNPL.PlotDoseError(model_cubes_2000_dose_err,'Cubes model, lr = 0.001, 200 samples per dataset, 2000 epochs, dose error',model_cubes_2000_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08dba4e",
   "metadata": {},
   "source": [
    "![model cubes 2000 dose error](Plots/model_cubes_2000_dose_err.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c3a4e32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,3,figsize=(30,10))\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "cubes_2000_AmBe_loss = NNPL.compare_pred_true(model_cubes_2000,testing_data_dir+AmBe_counts,testing_data_dir+AmBe_target,'AmBe','cubes only model,\\n 2000 epochs',ax[0],24,np.load(energy_bins),1,loss_fn)\n",
    "cubes_2000_AmLi_loss = NNPL.compare_pred_true(model_cubes_2000,testing_data_dir+AmLi_counts,testing_data_dir+AmLi_target,'AmLi','cubes only model,\\n 2000 epochs',ax[1],24,np.load(energy_bins),1,loss_fn)\n",
    "cubes_2000_Cf_loss = NNPL.compare_pred_true(model_cubes_2000,testing_data_dir+Cf_counts,testing_data_dir+Cf_target,r'$^{252}$Cf','cubes only model,\\n 2000 epochs',ax[2],24,np.load(energy_bins),1,loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f55a4a",
   "metadata": {},
   "source": [
    "![cubes model 2000 predictions](Plots/model_cubes_2000_prediction.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b7670f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AmBe loss: 0.0924101173877716\n",
      "AmLi loss: 0.02471756935119629\n",
      "Cf-252 loss: 0.034533705562353134\n"
     ]
    }
   ],
   "source": [
    "print(\"AmBe loss: {}\".format(cubes_2000_AmBe_loss))\n",
    "print(\"AmLi loss: {}\".format(cubes_2000_AmLi_loss))\n",
    "print(\"Cf-252 loss: {}\".format(cubes_2000_Cf_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecedc16d",
   "metadata": {},
   "source": [
    "### Cubes and profiles model, learning rate 0.001, 200 samples per dataset, trained for 2000 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc3ccf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "NNPL.PlotLosses([model_cubes_profiles_2000_tloss,model_cubes_profiles_2000_vloss],['Training loss','Validation loss'],'Cubes and profiles model, lr = 0.001, 200 samples per dataset, 2000 epochs',model_cubes_profiles_2000_epoch,log=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb5cc82",
   "metadata": {},
   "source": [
    "![Cubes profiles 2000 epochs loss](Plots/model_cubes_profiles_2000epochs_loss.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "717d8932",
   "metadata": {},
   "outputs": [],
   "source": [
    "NNPL.PlotDoseError(model_cubes_profiles_2000_dose_err,'Cubes and profiles model dose error',model_cubes_profiles_2000_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c92e300",
   "metadata": {},
   "source": [
    "![cubes profiles 2000 epochs dose error](Plots/model_cubes_profiles_2000epochs_dose_err.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "089a42ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1,3,figsize=(30,10))\n",
    "\n",
    "cubes_profiles_2000_AmBe_loss = NNPL.compare_pred_true(model_cubes_profiles_2000,testing_data_dir+'withProfiles/'+AmBe_counts,testing_data_dir+AmBe_target,'AmBe','cubes and \\n profiles model, 2000 epochs',ax[0],24,np.load(energy_bins),1,loss_fn)\n",
    "cubes_profiles_2000_AmLi_loss = NNPL.compare_pred_true(model_cubes_profiles_2000,testing_data_dir+'withProfiles/'+AmLi_counts,testing_data_dir+AmLi_target,'AmLi','cubes and \\n profiles model, 2000 epochs',ax[1],24,np.load(energy_bins),1,loss_fn)\n",
    "cubes_profiles_2000_Cf_loss = NNPL.compare_pred_true(model_cubes_profiles_2000,testing_data_dir+'withProfiles/'+Cf_counts,testing_data_dir+Cf_target,r'$^{252}$Cf','cubes and \\n profiles model, 2000 epochs',ax[2],24,np.load(energy_bins),1,loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f56c91",
   "metadata": {},
   "source": [
    "![cubes profiles 2000 predictions](Plots/model_cubes_profiles_2000_prediction.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
